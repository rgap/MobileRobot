
#include <iostream>
#include <pcl/io/pcd_io.h>
#include <pcl/point_types.h>
#include <pcl/console/parse.h>
#include <boost/thread/thread.hpp>

#include <pcl/filters/voxel_grid.h>

#include <pcl/filters/extract_indices.h>
#include <pcl/segmentation/extract_clusters.h>

 #include <pcl/kdtree/kdtree_flann.h>
 #include <pcl/features/normal_3d.h>
 #include <pcl/surface/gp3.h>

#include <pcl/keypoints/sift_keypoint.h>

using namespace std;

int main(int argc, char** argv) {

	/*
	 if (argc < 2) {
	 cout << "Not enough parameters";
	 return 0;
	 }
	 */

	pcl::PCDReader reader;
	pcl::PointCloud<pcl::PointXYZ>::Ptr cloud(
			new pcl::PointCloud<pcl::PointXYZ>), cloud_f(
			new pcl::PointCloud<pcl::PointXYZ>);

	reader.read(
			"/home/rgap/REPOSITORIES/MobileRobot/bin/clusters_kdtree/cloud_cluster_4.pcd",
			*cloud);
	cout << "PointCloud before filtering has: " << cloud->points.size()
			<< " data points." << endl;

	/* Cloud Downsampling - Voxel */
	pcl::VoxelGrid<pcl::PointXYZ> vg;
	vg.setInputCloud(cloud);
	vg.setLeafSize(0.01f, 0.01f, 0.01f);
	vg.filter(*cloud);
	cout << "PointCloud after filtering has: " << cloud->points.size()
			<< " data points." << endl;

	////////////////////////////////////////////////////////////

	/* Clustering */

	pcl::search::KdTree<pcl::PointXYZ>::Ptr tree(
			new pcl::search::KdTree<pcl::PointXYZ>);
	tree->setInputCloud(cloud);

	vector<pcl::PointIndices> cluster_indices;
	pcl::EuclideanClusterExtraction<pcl::PointXYZ> ec;
	ec.setClusterTolerance(0.02); // 2cm
	ec.setMinClusterSize(100);
	ec.setMaxClusterSize(25000);
	ec.setSearchMethod(tree);
	ec.setInputCloud(cloud);
	ec.extract(cluster_indices);

	cout << "# Clusters : " << cluster_indices.size() << endl;

	pcl::PCDWriter writer;
	int i = 0;
	for (vector<pcl::PointIndices>::const_iterator it = cluster_indices.begin(); it
			!= cluster_indices.end(); ++it) {
		pcl::PointCloud<pcl::PointXYZ>::Ptr cloud_cluster(
				new pcl::PointCloud<pcl::PointXYZ>);
		for (vector<int>::const_iterator pit = it->indices.begin(); pit
				!= it->indices.end(); pit++)
			cloud_cluster->points.push_back(cloud->points[*pit]);
		cloud_cluster->width = cloud_cluster->points.size();
		cloud_cluster->height = 1;
		cloud_cluster->is_dense = true;

		cout << "PointCloud representing the Cluster #" << i << " with "
				<< cloud_cluster->points.size() << " data points." << endl;
		stringstream ss;
		ss << "cloud_cluster_" << i << ".pcd";
		writer.write<pcl::PointXYZ> (ss.str(), *cloud_cluster, false);
		i++;

		/* Surface Reconstruction - Mesh */

		pcl::GreedyProjectionTriangulation<pcl::PointXYZRGBNormal>* gp3 = new pcl::GreedyProjectionTriangulation<pcl::PointXYZRGBNormal>;

		gp3->setSearchRadius (0.025); // Maximum distance between connected points (maximum edge length)
		gp3->setMu (2.5);
		gp3->setMaximumNearestNeighbors (100);
		gp3->setMaximumSurfaceAngle(M_PI/4); // 45 degrees
		gp3->setMinimumAngle(M_PI/18); // 10 degrees
		gp3->setMaximumAngle(2*M_PI/3); // 120 degrees
		gp3->setNormalConsistency(false);

		boost::shared_ptr<pcl::PCLSurfaceBase<pcl::PointXYZRGBNormal> > surface_reconstruction;
		surface_reconstruction.reset(gp3);

		/* Keypoint Detector */
		boost::shared_ptr<pcl::Keypoint<pcl::PointXYZRGB, pcl::PointXYZI> > keypoint_detector;

		pcl::SIFTKeypoint<pcl::PointXYZRGB, pcl::PointXYZI>* sift3D = new pcl::SIFTKeypoint<pcl::PointXYZRGB, pcl::PointXYZI>;
		sift3D->setScales(0.01, 3, 2);
		sift3D->setMinimumContrast(0.0);
		keypoint_detector.reset(sift3D);

		/* Process */
		//ICCVTutorial<pcl::FPFHSignature33> tutorial (keypoint_detector, feature_extractor, surface_reconstruction, source, target);
		//tutorial.run ();
	}

	return (0);
}



/*
#include <opencv2/opencv.hpp>

#include <stdio.h>
#include <string.h>
#include <unistd.h>
#include <SerialStream.h>
#include <iostream>

#include "globals.h"
#include "typedefs.h"

#include "Capture/DeviceCapture.h"
#include "RobotPlanning/RobotFSM.h"
#include "RobotVision.h"
#include "ModelParameters.h"

using namespace cv;
using namespace std;

//////////////////////////////// OPTIONS
#define COLLECT_CANS 1
#define SEND_SIGNALS 1
#define MOVE_KINECT 1

//////////////////////////////// GUI
ModelParameters* P = new ModelParameters();

//////////////////////////////// DOC
#define showFrame(namewindow, path, img) \
	if(showFrame) imshow(namewindow, img); if(save) imwrite(path, img);

#define keyboardActions(k) \
		if (save) save = 0;\
		if (k == 'q') save = 1;\
		else if (k == 'w') showFrame = !showFrame;


void initCallbacks() {
	namedWindow("PARAMS_CAN");

	createTrackbar("sigma", "PARAMS_CAN", &P->sigma, 255, NULL, NULL);
	createTrackbar("alpha", "PARAMS_CAN", &P->alpha, 255, NULL, NULL);
	createTrackbar("beta", "PARAMS_CAN", &P->beta, 255, NULL, NULL);
	createTrackbar("minH_can", "PARAMS_CAN", &P->minH_can, 255, NULL, NULL);
	createTrackbar("maxH_can", "PARAMS_CAN", &P->maxH_can, 255, NULL, NULL);
	createTrackbar("minS_can", "PARAMS_CAN", &P->minS_can, 255, NULL, NULL);
	createTrackbar("maxS_can", "PARAMS_CAN", &P->maxS_can, 255, NULL, NULL);
	createTrackbar("minV_can", "PARAMS_CAN", &P->minV_can, 255, NULL, NULL);
	createTrackbar("maxV_can", "PARAMS_CAN", &P->maxV_can, 255, NULL, NULL);
	createTrackbar("blurSize", "PARAMS_CAN", &P->blurSize, 51, NULL, NULL);
	createTrackbar("minArea", "PARAMS_CAN", &P->minArea, 50000, NULL, NULL);
	createTrackbar("maxArea", "PARAMS_CAN", &P->maxArea, 50000, NULL, NULL);
	createTrackbar("minApCuadrado", "PARAMS_CAN", &P->minApCuadrado_pos, 10,
			NULL, NULL);
	createTrackbar("maxApCuadrado", "PARAMS_CAN", &P->maxApCuadrado_pos, 10,
			NULL, NULL);

	namedWindow("PARAMS_DEPTH");
	createTrackbar("maxDepth", "PARAMS_DEPTH", &P->max_depth_pos, 20, NULL,
			NULL);
	createTrackbar("maxDistObstacle", "PARAMS_DEPTH", &P->maxDistObstacle_pos,
			30, NULL, NULL);
	createTrackbar("maxHeightFloor", "PARAMS_DEPTH", &P->maxHeightFloor_pos,
			480, NULL, NULL);
	createTrackbar("distThreshold", "PARAMS_DEPTH", &P->distThreshold_pos, 480,
			NULL, NULL);
	createTrackbar("axisVal", "PARAMS_DEPTH", &P->axisVal, 2, NULL, NULL);
	createTrackbar("epsAngle", "PARAMS_DEPTH", &P->epsAngle_pos, 3600, NULL,
			NULL);

	namedWindow("PARAMS_WATER");
	createTrackbar("minH_water", "PARAMS_WATER", &P->minH_water, 255, NULL,
			NULL);
	createTrackbar("maxH_water", "PARAMS_WATER", &P->maxH_water, 255, NULL,
			NULL);
	createTrackbar("minS_water", "PARAMS_WATER", &P->minS_water, 255, NULL,
			NULL);
	createTrackbar("maxS_water", "PARAMS_WATER", &P->maxS_water, 255, NULL,
			NULL);
	createTrackbar("minV_water", "PARAMS_WATER", &P->minV_water, 255, NULL,
			NULL);
	createTrackbar("maxV_water", "PARAMS_WATER", &P->maxV_water, 255, NULL,
			NULL);
}

/////////////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////////////


void frameLoop() {

	////////////////////////// HW
	//DeviceCapture device(2, "/home/rgap/REPOSITORIES/BeachCleaner/CloudTesting/dataset/kinect/meeting_small_1_1.png","/home/rgap/REPOSITORIES/BeachCleaner/CloudTesting/dataset/kinect/meeting_small_1_1_depth.png");
	DeviceCapture device(0);

	RobotVision vision;
	RobotFSM robot;

	vision.initializeVision(device.szFrame);
	vision.setParameters(P);
	initCallbacks();

	int k, save = 0, showFrame = 1;
	while (1) {

		device.verifyState();
		P->updateParameters();

		vision.imgBGR = device.getBGRFrame();
		showFrame("imgBGR", "TESTS/1_imgBGR.png", vision.imgBGR);

		vision.applyGaussBlur(vision.imgBGR, vision.imgBGR_Blur);
		showFrame("imgBGR_Blur", "TESTS/1_imgBGR_Blur.png", vision.imgBGR_Blur);

		vision.applyColorSegmentation_HSV(vision.imgBGR_Blur,
				vision.imgSegColor_Can);
		showFrame("can_HSV", "TESTS/1_imgSegColor_Can.png", vision.imgSegColor_Can);

		{
			vision.world = device.getDepthFrame();

			vision.getColorizeDisparity(device.getDisparityMap());
			showFrame("dispColor", "TESTS/1_disparityColorized.png", vision.disparityColorized);

			////////////////////////////////////// RANGO DE VISION
			vision.applyDepthThresholding(vision.world, vision.imgMaxDepth);
			showFrame("imgMaxDepth", "TESTS/1_imgMaxDepth.png", vision.imgMaxDepth);

			vision.applyShapeSegmentation(vision.imgSegColor_Can,
					vision.imgSegShape_Can);
			showFrame("imgSegShape_Can", "TESTS/1_imgSegShape_Can.png", vision.imgSegShape_Can);
			showFrame("imgBGR_cans_detected", "TESTS/1_imgBGR_cans_detected.png", vision.imgBGR);

			//vision.applyCloudDownsampling();

			////////////////////////////////////// OBTACLE RECOGNITION
			vision.applyObstacleRecognition(vision.imgBGR_Blur, vision.world,
					vision.imgSegShape_Can, vision.imgObstaclesBin);

			showFrame("imgObstaclesBin", "TESTS/1_imgObstaclesBin.png", vision.imgObstaclesBin);
			showFrame("imgPlane", "TESTS/1_imgPlane.png", vision.imgPlane);
		}
		{
			//robot.planWithEnvironment(vision.getPointNearestCan(),
			//		vision.imgObstaclesBin);
		}

		k = cv::waitKey(1);
		keyboardActions(k);
	}
}

int main() {
	frameLoop();
}

*/
